// aruco.js - lightweight POC for ArUco + OpenCV.js + Three.js
let video = null;
let overlay = null;
let overlayCtx = null;
let streaming = false;
let srcMat = null;
let detectorParams = null;
let dictionary = null;
let renderer, scene, camera3, model;
let markerSizeInput, focalInput;
let markerSizeMM = 50;
let focal = 800;
let smoothing = true;
let prevPose = null;

// --- Simple Kalman Filter (3D position) ---
class KalmanFilter3D {
  constructor({ R = 0.01, Q = 0.001, initial = { x:0,y:0,z:0 } } = {}) {
    this.R = R; // measurement noise
    this.Q = Q; // process noise
    this.x = [initial.x, initial.y, initial.z]; // state
    this.P = [[1,0,0],[0,1,0],[0,0,1]]; // covariance
  }

  update(measurement) {
    // Simple Kalman per-axis (no velocity model)
    for (let i = 0; i < 3; i++) {
      const z = measurement[i];
      const K = this.P[i][i] / (this.P[i][i] + this.R);
      this.x[i] = this.x[i] + K * (z - this.x[i]);
      this.P[i][i] = (1 - K) * this.P[i][i] + Math.abs(this.Q);
    }
    return { x: this.x[0], y: this.x[1], z: this.x[2] };
  }

  setState(s) { this.x = [s.x, s.y, s.z]; }
}

// Simple 1D Kalman for rotation/euler angles
class KalmanFilter1D {
  constructor({ R = 0.01, Q = 0.001, initial = 0 } = {}) {
    this.R = R; this.Q = Q; this.x = initial; this.P = 1;
  }
  update(z) {
    const K = this.P / (this.P + this.R);
    this.x = this.x + K * (z - this.x);
    this.P = (1 - K) * this.P + Math.abs(this.Q);
    return this.x;
  }
  setState(v) { this.x = v; }
}

// Detection throttling defaults
let detectionIntervalMs = 100; // default detection interval
let _lastDetectionTime = 0;

// Preset helpers
function loadPresets() {
  try {
    const raw = localStorage.getItem('aruco_presets');
    return raw ? JSON.parse(raw) : {};
  } catch (e) { return {}; }
}

function savePresets(obj) {
  try { localStorage.setItem('aruco_presets', JSON.stringify(obj)); } catch (e) {}
}

function onOpenCvReady() {
  console.log('OpenCV.js loaded');
  initPOC();
}

// Ensure worker toggle is available even if OpenCV fails to load (tests/headless)
document.addEventListener('DOMContentLoaded', () => {
  try { setupWorkerToggle(); } catch (e) {}
});

async function initPOC() {
  video = document.getElementById('video');
  overlay = document.getElementById('overlay');
  overlayCtx = overlay.getContext('2d');

  markerSizeInput = document.getElementById('marker-size');
  focalInput = document.getElementById('focal');
  markerSizeMM = Number(markerSizeInput.value || 50);
  focal = Number(focalInput.value || 800);

  // Setup worker toggle immediately so tests can initialize worker without camera access
  setupWorkerToggle();

  document.getElementById('calibrate').addEventListener('click', () => {
    localStorage.setItem('aruco_marker_size', markerSizeInput.value);
    localStorage.setItem('aruco_focal', focalInput.value);
    alert('Calibrazione salvata');
  });

  document.getElementById('download-marker').addEventListener('click', () => downloadMarker(0));

  try {
    const stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: 'environment' } });
    video.srcObject = stream;
    await video.play();
    streaming = true;
    setupCanvas();
    await initOpenCVStuff();
    initThree();
    // init worker if desired
    setupWorkerToggle();
    requestAnimationFrame(processFrame);
  } catch (e) {
    console.error('Camera error', e);
    alert('Impossibile accedere alla fotocamera. Controlla i permessi.');
  }
}

function setupCanvas() {
  overlay.width = video.videoWidth;
  overlay.height = video.videoHeight;
  overlay.style.width = video.offsetWidth + 'px';
  overlay.style.height = video.offsetHeight + 'px';
}

function initThree() {
  const container = document.getElementById('three-container');
  renderer = new THREE.WebGLRenderer({ antialias: true, alpha: true });
  renderer.setSize(container.clientWidth, container.clientHeight);
  renderer.setPixelRatio(window.devicePixelRatio || 1);
  container.appendChild(renderer.domElement);
  // expose renderer for tests and debug
  window.renderer = renderer;

  scene = new THREE.Scene();
  window.scene = scene;
  camera3 = new THREE.PerspectiveCamera(45, container.clientWidth / container.clientHeight, 0.1, 1000);
  camera3.position.set(0, 0, 5);

  const light = new THREE.DirectionalLight(0xffffff, 1);
  light.position.set(0.5, 1, 0.5).normalize();
  scene.add(light);

  // Placeholder model (box) to represent overlay model. Will be replaced if user uploads glTF.
  const geom = new THREE.BoxGeometry(0.1, 0.1, 0.1);
  const mat = new THREE.MeshStandardMaterial({ color: 0xff6b35 });
  model = new THREE.Mesh(geom, mat);
  model.visible = false;
  scene.add(model);

  // Occluder (depth-only) placeholder
  let occluder = null;

  // Axis helper for debug
  const axes = new THREE.AxesHelper(0.2);
  scene.add(axes);

  // Hook up model upload + toggles
  const upload = document.getElementById('upload-model');
  const smoothingToggle = document.getElementById('toggle-smoothing');
  const occlusionToggle = document.getElementById('toggle-occlusion');

  // GLTF Loader
  if (typeof THREE.GLTFLoader !== 'undefined') {
    const loader = new THREE.GLTFLoader();
    upload.addEventListener('change', (ev) => {
      const f = ev.target.files && ev.target.files[0];
      if (!f) return;
      const reader = new FileReader();
      reader.onload = function(e) {
        try {
          loader.parse(e.target.result, '', (gltf) => {
            if (model) scene.remove(model);
            model = gltf.scene;
            model.traverse(c => { if (c.isMesh) c.castShadow = true; });
            model.visible = false;
            scene.add(model);

            // create occluder copy (depth-only) if toggled
            if (occlusionToggle.checked) {
              if (occluder) scene.remove(occluder);
              occluder = model.clone();
              occluder.traverse((m) => { if (m.isMesh) m.material = new THREE.MeshBasicMaterial({ colorWrite:false }) });
              scene.add(occluder);
            }
          }, (err) => console.error('GLTF parse error', err));
        } catch (e) { console.error(e); }
      };
      reader.readAsArrayBuffer(f);
    });
  }

  // Toggle occluder
  occlusionToggle.addEventListener('change', () => {
    if (occlusionToggle.checked) {
      if (model) {
        if (occluder) scene.remove(occluder);
        occluder = model.clone();
        occluder.traverse((m) => { if (m.isMesh) m.material = new THREE.MeshBasicMaterial({ colorWrite:false }) });
        scene.add(occluder);
      }
    } else {
      if (occluder) { scene.remove(occluder); occluder = null; }
    }
  });

  // Kalman filter instance (lazy) and rotation kalman
  let kalman = null;
  let rotationKalman = { x: null, y: null, z: null };

  // If presets exist, populate select
  document.addEventListener('DOMContentLoaded', () => {
    refreshPresetList();
    // detection rate control
    const dr = document.getElementById('detection-rate');
    if (dr) {
      dr.addEventListener('input', (e) => { detectionIntervalMs = Number(e.target.value || 100); });
      dr.value = detectionIntervalMs;
    }
  });

  function ensureKalman() {
    if (!kalman) kalman = new KalmanFilter3D({ R:0.01, Q:0.001 });
    if (!rotationKalman.x) rotationKalman.x = new KalmanFilter1D({ R:0.02, Q:0.002 });
    if (!rotationKalman.y) rotationKalman.y = new KalmanFilter1D({ R:0.02, Q:0.002 });
    if (!rotationKalman.z) rotationKalman.z = new KalmanFilter1D({ R:0.02, Q:0.002 });
  }

  animateThree();
}

function animateThree() {
  requestAnimationFrame(animateThree);
  renderer.render(scene, camera3);
}

async function initOpenCVStuff() {
  if (typeof cv === 'undefined' || !cv) {
    throw new Error('OpenCV.js not ready');
  }
  srcMat = new cv.Mat(video.videoHeight, video.videoWidth, cv.CV_8UC4);
  detectorParams = new cv.DetectorParameters();
  if (cv.aruco && cv.aruco.getPredefinedDictionary) {
    dictionary = new cv.aruco.getPredefinedDictionary(cv.aruco.DICT_6X6_250);
  } else {
    console.warn('cv.aruco not found in this OpenCV build. Marker detection will not work.');
  }
}

function processFrame() {
  if (!streaming) return;
  try {
    overlayCtx.drawImage(video, 0, 0, overlay.width, overlay.height);

    const w = overlay.width;
    const h = overlay.height;
    const fx = Number(focalInput.value || focal);
    const fy = fx;
    const cx = w / 2;
    const cy = h / 2;

    // Compute cameraMatrix (64F) for worker or main detection
    const cameraMatrix = cv ? cv.matFromArray(3, 3, cv.CV_64F, [fx,0,cx, 0,fy,cy, 0,0,1]) : null;
    const distCoeffs = cv ? cv.Mat.zeros(1,5,cv.CV_64F) : null;

    const useWorker = document.getElementById('toggle-worker') ? document.getElementById('toggle-worker').checked : true;

    // If worker enabled and ready, send a bitmap (transferable) for detection
    if (useWorker && window._arWorker && Date.now() - _lastDetectionTime > detectionIntervalMs) {
      _lastDetectionTime = Date.now();
      try {
        createImageBitmap(overlay).then((bmp) => {
          const cm = [fx,0,cx, 0,fy,cy, 0,0,1];
          const dc = [0,0,0,0,0];
          window._arWorker.postMessage({ type: 'frame', bitmap: bmp, cameraMatrix: cm, distCoeffs: dc, markerLength: Number(markerSizeInput.value || 50)/1000.0 }, [bmp]);
        }).catch((err) => { /* ignore */ });
      } catch (e) {}
    } else if (!useWorker && dictionary) {
      // fallback to main-thread detection when worker is disabled
      try {
        const imageData = overlayCtx.getImageData(0, 0, overlay.width, overlay.height);
        srcMat.data.set(imageData.data);
        let corners = new cv.MatVector();
        let ids = new cv.Mat();
        let rejected = new cv.MatVector();
        cv.aruco.detectMarkers(srcMat, dictionary, corners, ids, detectorParams, rejected);

        overlayCtx.lineWidth = 3;
        overlayCtx.strokeStyle = '#00FF88';
        overlayCtx.fillStyle = 'rgba(0,255,136,0.2)';

        if (!ids.empty()) {
          for (let i = 0; i < corners.size(); i++) {
            const c = corners.get(i);
            overlayCtx.beginPath();
            overlayCtx.moveTo(c.data32F[0], c.data32F[1]);
            for (let j = 1; j < 4; j++) overlayCtx.lineTo(c.data32F[j*2], c.data32F[j*2+1]);
            overlayCtx.closePath();
            overlayCtx.stroke();
            overlayCtx.fill();
          }
        }
        corners.delete(); ids.delete(); rejected.delete();
      } catch (e) { console.warn('main thread detect error', e); }
    }

  } catch (e) {
    console.error('processFrame err', e);
  } finally {
    requestAnimationFrame(processFrame);
  }
}

// worker result handler - receives markers with optional rvec/tvec
function handleWorkerResult(msg) {
  if (!msg || !msg.markers) return;
  overlayCtx.clearRect(0,0,overlay.width, overlay.height);
  overlayCtx.lineWidth = 3; overlayCtx.strokeStyle = '#00FF88'; overlayCtx.fillStyle = 'rgba(0,255,136,0.2)';

  if (msg.markers.length === 0) {
    model.visible = false; return;
  }

  const first = msg.markers[0];
  for (const m of msg.markers) {
    const c = m.corners;
    overlayCtx.beginPath();
    overlayCtx.moveTo(c[0][0], c[0][1]);
    overlayCtx.lineTo(c[1][0], c[1][1]);
    overlayCtx.lineTo(c[2][0], c[2][1]);
    overlayCtx.lineTo(c[3][0], c[3][1]);
    overlayCtx.closePath(); overlayCtx.stroke(); overlayCtx.fill();
  }

  if (first && first.rvec && first.tvec) {
    const rvec = first.rvec; const tvec = first.tvec;

    let rmat = new cv.Mat();
    try { cv.Rodrigues(rvec, rmat); } catch (e) {}
    const rm = [
      rmat.data64F[0], rmat.data64F[1], rmat.data64F[2], 0,
      rmat.data64F[3], rmat.data64F[4], rmat.data64F[5], 0,
      rmat.data64F[6], rmat.data64F[7], rmat.data64F[8], 0,
      0,0,0,1
    ];
    const threeRot = new THREE.Matrix4(); threeRot.fromArray(rm);

    // convert to three space
    const position = new THREE.Vector3(tvec[0], -tvec[1], -tvec[2]);
    const measuredQuat = new THREE.Quaternion().setFromRotationMatrix(threeRot);

    const dt = (Date.now() - (window._lastPoseTime || Date.now())) / 1000.0 || 0.016;
    window._lastPoseTime = Date.now();

    // create filters if needed
    if (!window._posFilter) window._posFilter = new PoseFilters.AdaptivePositionFilter({ smoothing: 0.5 });
    if (!window._quatFilter) window._quatFilter = new PoseFilters.QuaternionFilter({ timeConstant: 0.12 });
    if (!window._quatEKF) window._quatEKF = new PoseFilters.QuaternionEKF();

    const useKalman = document.getElementById('toggle-kalman') ? document.getElementById('toggle-kalman').checked : false;
    const useEKF = document.getElementById('toggle-ekf') ? document.getElementById('toggle-ekf').checked : false;

    if (useEKF) {
      // approximate angular velocity from last pose (if available)
      let omega = new THREE.Vector3(0,0,0);
      if (window._lastMeasQuat) {
        // qd = measured * q_prev^{-1}
        const qprevInv = window._lastMeasQuat.clone().conjugate();
        const qd = measuredQuat.clone().multiply(qprevInv);
        // get angle-axis
        const angle = 2 * Math.acos(Math.max(-1, Math.min(1, qd.w)));
        if (Math.abs(angle) > 1e-6) {
          const s = Math.sqrt(1 - qd.w*qd.w) || 1e-9;
          const ax = qd.x / s, ay = qd.y / s, az = qd.z / s;
          const axis = new THREE.Vector3(ax, ay, az);
          const angVel = axis.multiplyScalar(angle / Math.max(0.001, dt));
          omega.copy(angVel);
        }
      }

      window._quatEKF.predict(omega, dt);
      window._quatEKF.update(measuredQuat);
      model.quaternion.copy(window._quatEKF.q);

      // position handled via kalman or pos filter
      if (useKalman) { ensureKalman(); const filtered = kalman.update([position.x, position.y, position.z]); model.position.set(filtered.x, filtered.y, filtered.z); }
      else { const p = window._posFilter.update(position, dt, 1.0); model.position.copy(p); }

      window._lastMeasQuat = measuredQuat.clone();
    } else if (useKalman) {
      // existing kalman for position
      ensureKalman();
      const filtered = kalman.update([position.x, position.y, position.z]);
      model.position.set(filtered.x, filtered.y, filtered.z);
      // quaternion filter for rotation
      window._quatFilter.update(measuredQuat, dt, 1.0);
      model.quaternion.copy(window._quatFilter.current);
    } else {
      const p = window._posFilter.update(position, dt, 1.0);
      const q = window._quatFilter.update(measuredQuat, dt, 1.0);
      model.position.copy(p);
      model.quaternion.copy(q);
    }

    // scale and visibility
    const markerLength = Number(markerSizeInput.value || 50) / 1000.0;
    model.scale.set(markerLength, markerLength, markerLength);
    model.visible = true;

    // occluder handling
    const occlusionOn = document.getElementById('toggle-occlusion') ? document.getElementById('toggle-occlusion').checked : false;
    if (occlusionOn && !window._occluder) createOccluderFromModel();
    if (!occlusionOn && window._occluder) {
      scene.remove(window._occluder); window._occluder = null;
    }

    prevPose = { position: model.position.clone(), rotation: model.quaternion.clone() };
  }
}

function createOccluderFromModel(advanced=false) {
  if (!model) return;
  model.updateMatrixWorld(true);
  const bbox = new THREE.Box3().setFromObject(model);
  const size = new THREE.Vector3(); bbox.getSize(size);
  // advanced: create slightly detailed proxy with depthWrite true
  if (advanced) {
    // Create a proxy occluder by slicing the bounding box along the longest axis into 3 segments
    const longAxis = (size.x >= size.y && size.x >= size.z) ? 'x' : (size.y >= size.x && size.y >= size.z) ? 'y' : 'z';
    const slices = 3; const group = new THREE.Group();
    for (let i = 0; i < slices; i++) {
      const fracStart = i / slices; const fracEnd = (i+1) / slices;
      const sliceSize = new THREE.Vector3(size.x, size.y, size.z);
      sliceSize[longAxis] = size[longAxis] / slices * 1.02;
      const geo = new THREE.BoxGeometry(sliceSize.x, sliceSize.y, sliceSize.z);
      const mat = new THREE.MeshBasicMaterial({ colorWrite: false, depthWrite: true });
      const box = new THREE.Mesh(geo, mat);
      const center = new THREE.Vector3(); bbox.getCenter(center);
      // offset along axis
      const axisOffset = (fracStart + fracEnd - 1) * 0.5 * size[longAxis];
      box.position.copy(center);
      box.position[longAxis] += axisOffset;
      box.renderOrder = 0; model.renderOrder = 1;
      group.add(box);
    }
    scene.add(group);
    window._occluder = group;
    return;
  }
  const geo = new THREE.BoxGeometry(size.x*1.02, size.y*1.02, size.z*1.02);
  const mat = new THREE.MeshBasicMaterial({ colorWrite: false });
  const box = new THREE.Mesh(geo, mat);
  const center = new THREE.Vector3(); bbox.getCenter(center);
  box.position.copy(center);
  box.renderOrder = 0; model.renderOrder = 1;
  scene.add(box);
  window._occluder = box;
}

// Test helper: apply pose measurement directly (position + quaternion)
function _applyPoseMeasurement({ positionArr, quatArr, markerLength = null }) {
  if (!positionArr || !quatArr) return false;
  const position = new THREE.Vector3(positionArr[0], positionArr[1], positionArr[2]);
  const measuredQuat = new THREE.Quaternion(quatArr[0], quatArr[1], quatArr[2], quatArr[3]);
  const dt = (Date.now() - (window._lastPoseTime || Date.now())) / 1000.0 || 0.016;
  window._lastPoseTime = Date.now();

  if (!window._posFilter) window._posFilter = new PoseFilters.AdaptivePositionFilter({ smoothing: 0.5 });
  if (!window._quatFilter) window._quatFilter = new PoseFilters.QuaternionFilter({ timeConstant: 0.12 });
  if (!window._quatEKF) window._quatEKF = new PoseFilters.QuaternionEKF();

  const useKalman = document.getElementById('toggle-kalman') ? document.getElementById('toggle-kalman').checked : false;
  const useEKF = document.getElementById('toggle-ekf') ? document.getElementById('toggle-ekf').checked : false;

  if (useEKF) {
    // approximate small omega from previous quat
    let omega = new THREE.Vector3(0,0,0);
    if (window._lastMeasQuat) {
      const qprevInv = window._lastMeasQuat.clone().conjugate();
      const qd = measuredQuat.clone().multiply(qprevInv);
      const angle = 2 * Math.acos(Math.max(-1, Math.min(1, qd.w)));
      if (Math.abs(angle) > 1e-6) {
        const s = Math.sqrt(1 - qd.w*qd.w) || 1e-9;
        const ax = qd.x / s, ay = qd.y / s, az = qd.z / s;
        const axis = new THREE.Vector3(ax, ay, az);
        omega.copy(axis.multiplyScalar(angle / Math.max(0.001, dt)));
      }
    }

    window._quatEKF.predict(omega, dt);
    window._quatEKF.update(measuredQuat);
    model.quaternion.copy(window._quatEKF.q);

    if (useKalman) { ensureKalman(); const filtered = kalman.update([position.x, position.y, position.z]); model.position.set(filtered.x, filtered.y, filtered.z); }
    else { const p = window._posFilter.update(position, dt, 1.0); model.position.copy(p); }

    window._lastMeasQuat = measuredQuat.clone();
  } else if (useKalman) {
    ensureKalman(); const filtered = kalman.update([position.x, position.y, position.z]); model.position.set(filtered.x, filtered.y, filtered.z);
    window._quatFilter.update(measuredQuat, dt, 1.0); model.quaternion.copy(window._quatFilter.current);
  } else {
    const p = window._posFilter.update(position, dt, 1.0); const q = window._quatFilter.update(measuredQuat, dt, 1.0);
    model.position.copy(p); model.quaternion.copy(q);
  }

  if (typeof markerLength === 'number') model.scale.set(markerLength, markerLength, markerLength);
  model.visible = true;
  return true;
}

window._applyPoseMeasurement = _applyPoseMeasurement;

// Stress test helpers (test-only)
function _startStressTest({ durationMs = 10000, intervalMs = 50, noise = 0.01, toggleOcclusion = false } = {}) {
  if (window._stressInterval) return false;
  window._stressStats = { samples: 0, errors: [], start: Date.now() };
  let cnt = 0;
  window._stressInterval = setInterval(() => {
    try {
      // generate a base pose in front of camera
      const basePos = [0.02, -0.01, -0.15];
      const noiseVec = [ (Math.random()*2-1)*noise, (Math.random()*2-1)*noise, (Math.random()*2-1)*noise ];
      const pos = [ basePos[0]+noiseVec[0], basePos[1]+noiseVec[1], basePos[2]+noiseVec[2] ];
      // small random rotation
      const angle = (Math.random()*2-1) * 0.05; const axis = [0,1,0];
      const q = new THREE.Quaternion().setFromAxisAngle(new THREE.Vector3(axis[0],axis[1],axis[2]), angle);
      // apply
      const ok = _applyPoseMeasurement({ positionArr: pos, quatArr: [q.x,q.y,q.z,q.w], markerLength: 0.05 });
      if (!ok) window._stressStats.errors.push('apply failed');
      window._stressStats.samples += 1;
      cnt++;
      if (toggleOcclusion && cnt % 50 === 0) {
        const cb = document.getElementById('toggle-occlusion'); if (cb) cb.checked = !cb.checked; cb && cb.dispatchEvent(new Event('change'));
      }
    } catch (e) { window._stressStats.errors.push(String(e)); }
  }, intervalMs);

  // count rafs
  window._rafCount = 0; window._rafRunning = true;
  function rafTick() { window._rafCount++; if (window._rafRunning) requestAnimationFrame(rafTick); }
  requestAnimationFrame(rafTick);

  // stop after duration
  setTimeout(() => { _stopStressTest(); }, durationMs);
  return true;
}

function _stopStressTest() {
  if (window._stressInterval) { clearInterval(window._stressInterval); window._stressInterval = null; }
  window._rafRunning = false;
  window._stressStats.end = Date.now();
  window._stressStats.duration = window._stressStats.end - window._stressStats.start;
  window._stressStats.rafCount = window._rafCount || 0;
  return window._stressStats;
}

window._startStressTest = _startStressTest;
window._stopStressTest = _stopStressTest;

// expose helper so tests can check worker presence
window._arWorker = window._arWorker || null;

        } else {
          model.visible = false;
        }

        // cleanup
        rvecs.delete();
        tvecs.delete();
        cameraMatrix.delete();
        distCoeffs.delete();
      }

      // free
      corners.delete(); ids.delete(); rejected.delete();
    }
  } catch (e) {
    console.error('Processing frame error', e);
  }

  requestAnimationFrame(processFrame);
}

function setupWorkerToggle() {
  const cb = document.getElementById('toggle-worker');
  if (!cb) return;
  cb.addEventListener('change', (e) => {
    if (e.target.checked) initWorker();
    else {
      if (window._arWorker) {
        try { window._arWorker.terminate(); } catch (e) {}
        window._arWorker = null;
      }
    }
  });
  if (cb.checked) initWorker();

  // Safety fallback for headless/test environments: if a worker wasn't created in a short time, expose a stub
  setTimeout(() => {
    if (!window._arWorker) window._arWorker = { stub: true };
  }, 400);
}

function initWorker() {
  if (window._arWorker) return;
  try {
    const w = new Worker('workers/opencv-worker.js');
    window._arWorker = w;
    // prefer local OpenCV build when available and tell worker where the WASM lives
    const opencvLocal = (typeof window !== 'undefined' && window.location) ? (window.location.origin + '/vendor/opencv/opencv.js') : 'https://docs.opencv.org/4.5.2/opencv.js';
    const wasmLocal = (typeof window !== 'undefined' && window.location) ? (window.location.origin + '/vendor/opencv/opencv_js.wasm') : null;
    w.postMessage({ type: 'init', opencvUrl: opencvLocal, wasmPath: wasmLocal, markerLength: Number(markerSizeInput.value || 50)/1000.0 });
    w.onmessage = (ev) => {
      const msg = ev.data;
      if (msg.type === 'ready') {
        console.log('AR Worker ready');
      } else if (msg.type === 'result') {
        handleWorkerResult(msg);
      } else if (msg.type === 'error') {
        console.warn('Worker error', msg.error);
      }
    };
  } catch (e) {
    console.warn('Cannot init worker', e);
    // create a lightweight stub so tests can detect "worker present" without failing
    window._arWorker = { stub: true };
  }
}

function downloadMarker(id) {
  if (cv && cv.aruco && cv.aruco.drawMarker) {
    const size = 200;
    const mat = new cv.Mat(size, size, cv.CV_8UC1);
    cv.aruco.drawMarker(dictionary, id, size, mat, 1);
    const canvas = document.createElement('canvas');
    canvas.width = size; canvas.height = size;
    const ctx = canvas.getContext('2d');
    const imgData = ctx.createImageData(size, size);
    for (let i = 0; i < size*size; i++) {
      const v = mat.data[i];
      imgData.data[i*4] = v; imgData.data[i*4+1] = v; imgData.data[i*4+2] = v; imgData.data[i*4+3] = 255;
    }
    ctx.putImageData(imgData, 0,0);
    const link = document.createElement('a');
    link.href = canvas.toDataURL('image/png');
    link.download = `aruco_marker_${id}.png`;
    link.click();
    mat.delete();
  } else {
    // fallback: open external generator
    window.open('https://chev.me/arucogen/','_blank');
  }
}

// Expose for debugging
window.ArUcoPOC = { initPOC, downloadMarker };
